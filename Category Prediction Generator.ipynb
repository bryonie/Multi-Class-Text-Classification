{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file will be used to get data and out Category predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required modules from requirements.txt\n",
    "\n",
    "if requirements.txt is not present, please request it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: imblearn==0.0 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from -r requirements.txt (line 1)) (0.0)You are using pip version 19.0.3, however version 20.1.1 is available.\nYou should consider upgrading via the 'python -m pip install --upgrade pip' command.\n\nRequirement already satisfied: nltk==3.5 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from -r requirements.txt (line 2)) (3.5)\nRequirement already satisfied: numpy==1.18.4 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from -r requirements.txt (line 3)) (1.18.4)\nRequirement already satisfied: pandas==1.0.3 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from -r requirements.txt (line 4)) (1.0.3)\nRequirement already satisfied: scikit_learn==0.23.1 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from -r requirements.txt (line 5)) (0.23.1)\nRequirement already satisfied: spacy==2.2.4 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from -r requirements.txt (line 6)) (2.2.4)\nRequirement already satisfied: xgboost==1.1.0 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from -r requirements.txt (line 7)) (1.1.0)\nRequirement already satisfied: xlrd==1.2.0 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from -r requirements.txt (line 8)) (1.2.0)\nRequirement already satisfied: imbalanced-learn in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from imblearn==0.0->-r requirements.txt (line 1)) (0.6.2)\nRequirement already satisfied: click in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk==3.5->-r requirements.txt (line 2)) (7.1.2)\nRequirement already satisfied: joblib in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk==3.5->-r requirements.txt (line 2)) (0.15.1)\nRequirement already satisfied: regex in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk==3.5->-r requirements.txt (line 2)) (2020.5.14)\nRequirement already satisfied: tqdm in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk==3.5->-r requirements.txt (line 2)) (4.46.0)\nRequirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\micks\\appdata\\roaming\\python\\python37\\site-packages (from pandas==1.0.3->-r requirements.txt (line 4)) (2.8.1)\nRequirement already satisfied: pytz>=2017.2 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pandas==1.0.3->-r requirements.txt (line 4)) (2020.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit_learn==0.23.1->-r requirements.txt (line 5)) (2.0.0)\nRequirement already satisfied: scipy>=0.19.1 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit_learn==0.23.1->-r requirements.txt (line 5)) (1.4.1)\nRequirement already satisfied: setuptools in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy==2.2.4->-r requirements.txt (line 6)) (40.8.0)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy==2.2.4->-r requirements.txt (line 6)) (3.0.2)\nRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy==2.2.4->-r requirements.txt (line 6)) (0.6.0)\nRequirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy==2.2.4->-r requirements.txt (line 6)) (1.0.2)\nRequirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy==2.2.4->-r requirements.txt (line 6)) (0.4.1)\nRequirement already satisfied: thinc==7.4.0 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy==2.2.4->-r requirements.txt (line 6)) (7.4.0)\nRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy==2.2.4->-r requirements.txt (line 6)) (1.0.0)\nRequirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy==2.2.4->-r requirements.txt (line 6)) (1.1.3)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy==2.2.4->-r requirements.txt (line 6)) (2.0.3)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy==2.2.4->-r requirements.txt (line 6)) (2.23.0)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy==2.2.4->-r requirements.txt (line 6)) (1.0.2)\nRequirement already satisfied: six>=1.5 in c:\\users\\micks\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil>=2.6.1->pandas==1.0.3->-r requirements.txt (line 4)) (1.14.0)\nRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\micks\\appdata\\roaming\\python\\python37\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.4->-r requirements.txt (line 6)) (1.6.0)\nRequirement already satisfied: idna<3,>=2.5 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4->-r requirements.txt (line 6)) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4->-r requirements.txt (line 6)) (1.25.9)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4->-r requirements.txt (line 6)) (2020.4.5.1)\nRequirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4->-r requirements.txt (line 6)) (3.0.4)\nRequirement already satisfied: zipp>=0.5 in c:\\users\\micks\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy==2.2.4->-r requirements.txt (line 6)) (3.1.0)\nRequirement already satisfied: nl_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/nl_core_news_sm-2.2.5/nl_core_news_sm-2.2.5.tar.gz#egg=nl_core_news_sm==2.2.5 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (2.2.5)You are using pip version 19.0.3, however version 20.1.1 is available.\nYou should consider upgrading via the 'python -m pip install --upgrade pip' command.\n\nRequirement already satisfied: spacy>=2.2.2 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nl_core_news_sm==2.2.5) (2.2.4)\nRequirement already satisfied: setuptools in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.2.2->nl_core_news_sm==2.2.5) (40.8.0)\nRequirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.2.2->nl_core_news_sm==2.2.5) (1.0.2)\nRequirement already satisfied: numpy>=1.15.0 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.2.2->nl_core_news_sm==2.2.5) (1.18.4)\nRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.2.2->nl_core_news_sm==2.2.5) (1.0.0)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.2.2->nl_core_news_sm==2.2.5) (3.0.2)\nRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.2.2->nl_core_news_sm==2.2.5) (0.6.0)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.2.2->nl_core_news_sm==2.2.5) (1.0.2)\nRequirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.2.2->nl_core_news_sm==2.2.5) (1.1.3)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.2.2->nl_core_news_sm==2.2.5) (4.46.0)\nRequirement already satisfied: thinc==7.4.0 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.2.2->nl_core_news_sm==2.2.5) (7.4.0)\nRequirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.2.2->nl_core_news_sm==2.2.5) (0.4.1)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.2.2->nl_core_news_sm==2.2.5) (2.0.3)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.2.2->nl_core_news_sm==2.2.5) (2.23.0)\nRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\micks\\appdata\\roaming\\python\\python37\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->nl_core_news_sm==2.2.5) (1.6.0)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->nl_core_news_sm==2.2.5) (2020.4.5.1)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->nl_core_news_sm==2.2.5) (1.25.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->nl_core_news_sm==2.2.5) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in c:\\users\\micks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->nl_core_news_sm==2.2.5) (2.9)\nRequirement already satisfied: zipp>=0.5 in c:\\users\\micks\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->nl_core_news_sm==2.2.5) (3.1.0)\n✔ Download and installation successful\nYou can now load the model via spacy.load('nl_core_news_sm')\n"
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt\n",
    "!{sys.executable} -m spacy download nl_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nl_core_news_sm\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import re\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "import xlrd\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from sklearn import svm, datasets\n",
    "import joblib\n",
    "import pickle\n",
    "import easygui\n",
    "import time\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Lemmatizer method\n",
    "\n",
    "This method recieves a Series of incedent report texts\n",
    "\n",
    "This method returns a Series of the Lemmatized texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_lemmatizer_(data):\n",
    "    return [(token.lemma_) for token in nlp(data) if not token.is_digit and not token.is_punct and not token.is_space]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing method\n",
    "\n",
    "This method takes one argument:\n",
    "- Dataframe containing Incident Reports\n",
    "\n",
    "User will need to enter the column name that contains the incident report text\n",
    "\n",
    "This method returns preprocessed a Series of Incident Report texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    print(\"\\n******************** Data Preprocessing ******************\\n\")\n",
    "\n",
    "    column_name = \"\"\n",
    "    column_exists = False\n",
    "\n",
    "    while(column_name == \"\" or column_exists == False):\n",
    "        column_name = input(\"Please indicate what column contains the Incident Reports: \")\n",
    "        print(\"Column Name: \", column_name)\n",
    "        for col in data.columns:\n",
    "            if(str(column_name) == str(col)):\n",
    "                column_exists = True\n",
    "                break\n",
    "\n",
    "        if(column_exists == False):\n",
    "            print(\"The column name you provided does not exist!\")\n",
    "\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "    stopword_list = set(nltk.corpus.stopwords.words('dutch'))\n",
    "\n",
    "    #add words that aren't in the NLTK stopwords list\n",
    "    added_stopwords = [\"b\", \"u\", \"e\", \"ste\", \"kv\", \"aa\", \"a9\", \"mtr\", '+', '1e', '2e', '<', '>', 'a', 'a1', 'a12', 'a2', 'a9',\"één\", \"gis\", \"app\", \"h\", 'o.a.', 'oa', 'en/of', \"uur\"\n",
    "    \"km\", \"mm\", \"v\", \"kg\", \"cm\", \"mm²\", \"mm2\", \"0ngever\", \"e\", \"de\", \"m\"]\n",
    "    updated_stopword_list = stopword_list.union(added_stopwords)\\\n",
    "\n",
    "    # Dutch spacy tokens \n",
    "    # nlp = nl_core_news_sm.load()\n",
    "\n",
    "    def custom_lemmatizer(data):\n",
    "        return [(token.lemma_) for token in nlp(data) if not token.is_digit and not token.is_punct and not token.is_space]\n",
    "\n",
    "    print(\"Loading Vectorizer...\")\n",
    "    \n",
    "    # tfidf_vectorizer = TfidfVectorizer(max_features=12000,  stop_words=updated_stopword_list, max_df= 0.5, tokenizer=custom_lemmatizer)\n",
    "    # tfidf_vectorizer = joblib.load(\"tfidf_vectorizer.sav\")\n",
    "    tfidf_vectorizer = pickle.load(open(\"tfidf_vectorizer.pickle\", \"rb\"))\n",
    "\n",
    "    print(\"Data Preprocessing...\")\n",
    "    text = data[column_name].astype(str)\n",
    "    text = text.to_numpy()\n",
    "    # text_tfidf = tfidf_vectorizer.fit(text)\n",
    "    tfidf_text_val = tfidf_vectorizer.transform(text)\n",
    "\n",
    "    return tfidf_text_val, column_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Method\n",
    "\n",
    "This method takes two arguments: \n",
    "- A model\n",
    "- A Series of incident texts\n",
    "\n",
    "This method then saves a file with the predicted results\n",
    "\n",
    "Predict file columns:\n",
    "- Incident Report\n",
    "- Model Classification\n",
    "- Probability Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, text, data, column):\n",
    "    print(\"\\n******************** Getting Predictions ******************\\n\")\n",
    "    prob = model.predict(text) #Get predictions\n",
    "    prob_score = model.predict_proba(text) #Get prediction probsblity scores\n",
    "    prob_results = {\"Incident_ID\": [],\"Incident_Report\":[],\"Model_Classification\":[], \"Probability_Scores\": []}\n",
    "    output_filename = \"\"\n",
    "\n",
    "    print(\"*Output will automatically be an Excel file (.xlsx)\")\n",
    "    \n",
    "    while(output_filename == \"\"):\n",
    "        output_filename = input(\"Please enter output file name: \")\n",
    "    \n",
    "    for i in range (0,prob.size):\n",
    "        scores = []\n",
    "        prob_results[\"Incident_ID\"].append(data[\"Nr.\"])\n",
    "        prob_results[\"Incident_Report\"].append(data[column][i])\n",
    "        prob_results[\"Model_Classification\"].append(prob_results[i])\n",
    "        prob_results[\"Probability_Score\"].append(prob_score[i])\n",
    "\n",
    "        p = ((i + 1) / prob.size) * 100\n",
    "        print (\"Creating Predict File: {}%\".format(round(p,2)), end=\"\\r\")\n",
    "\n",
    "    Prob_Results = pd.DataFrame(prob_results)\n",
    "\n",
    "    Prob_Results.to_excel(output_filename, index=False)\n",
    "    print(\"\\nResults were saved in file: \", output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main (index) Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "***************************************************************\nWelcome to the Indicent Report Classification System!\n***************************************************************\n\nPlease select file (.xlsx or .csv): \n\n******************** Data Preprocessing ******************\n\nColumn Name:  Beschrijving incident\nLoading Vectorizer...\n[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\micks\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'custom_lemmatizer' on <module '__main__'>",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d392d4793797>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-d392d4793797>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mget_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-99a1f3b5536b>\u001b[0m in \u001b[0;36mpreprocessing\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# tfidf_vectorizer = TfidfVectorizer(max_features=12000,  stop_words=updated_stopword_list, max_df= 0.5, tokenizer=custom_lemmatizer)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# tfidf_vectorizer = joblib.load(\"tfidf_vectorizer.sav\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mtfidf_vectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tfidf_vectorizer.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data Preprocessing...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'custom_lemmatizer' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"***************************************************************\")\n",
    "    print(\"Welcome to the Indicent Report Classification System!\")\n",
    "    print(\"***************************************************************\\n\")\n",
    "\n",
    "    try:\n",
    "        print(\"Please select file (.xlsx or .csv): \")\n",
    "        filename = easygui.fileopenbox()\n",
    "    except ValueError:\n",
    "        print(\"\\nPlease enter a valid file!\")\n",
    "        print(\"Please try again!\")\n",
    "    except:\n",
    "        print(\"Something went wrong, please ty again or conact... Somebody...\")\n",
    "\n",
    "    model_name = \"Category Ongeval(pototype).sav\"\n",
    "\n",
    "    # Dutch spacy tokens \n",
    "    nlp = nl_core_news_sm.load()\n",
    "\n",
    "    data = pd.read_excel(filename)\n",
    "\n",
    "    model = joblib.load(model_name)\n",
    "\n",
    "    text, column_name = preprocessing(data)\n",
    "\n",
    "    get_predictions(model, text, data, column_name)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "C:\\Users\\micks\\Projects\\Candi Saftey Data Classification\\Heijmans data final.xlsx\n"
    }
   ],
   "source": [
    "filename = easygui.fileopenbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n*Output will automatically be an Excel file (.xlsx)\nBread.xlsx\n"
    }
   ],
   "source": [
    "output_filename = \"\"\n",
    "print(len(output_filename))\n",
    "\n",
    "print(\"*Output will automatically be an Excel file (.xlsx)\")\n",
    "    \n",
    "while(output_filename == \"\"):\n",
    "    output_filename = input(\"Please enter output file name: \")\n",
    "\n",
    "output_filename += \".xlsx\"\n",
    "\n",
    "print(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bit7f6d5ef80ac84f0dbc4f0d76a489c0fa",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}