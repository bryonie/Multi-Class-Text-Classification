{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "^C\nNote: you may need to restart the kernel to use updated packages.\n"
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7c488f03cf66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnl_core_news_sm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nl_core_news_sm\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import re\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data \n",
    "data_1= pd.read_excel(\"./Heijmans data final.xlsx\")\n",
    "#data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18516, 6)\n",
      "Column Count\n",
      "ID_num                  18516\n",
      "Incident_Description    17909\n",
      "Sub_Categories           3276\n",
      "Reason_Categories        2340\n",
      "Main_Categories          3307\n",
      "Incident_Date           18516\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Null Count \n",
      "ID_num                      0\n",
      "Incident_Description      607\n",
      "Sub_Categories          15240\n",
      "Reason_Categories       16176\n",
      "Main_Categories         15209\n",
      "Incident_Date               0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Unique_main_categories: 10\n",
      "Unique_subcategories: 43\n",
      "Unique_reasons: 154\n",
      "\n",
      "\n",
      "Main_Categories\n",
      "Aanrijding                                      5.624433\n",
      "Agressie en extreme lichamelijke inspanning     2.056244\n",
      "Andere vormen van contact met voorwerpen       14.454188\n",
      "BHV inzet op locatie                            3.386755\n",
      "Gevaarlijke atmosfeer                           0.302389\n",
      "Gevaarlijke stoffen, brand en explosies         3.144844\n",
      "Gezondheidsschade                               0.514061\n",
      "Machines en handgereedschap                    12.760810\n",
      "Vallen (van personen of voorwerpen)            45.539764\n",
      "overig                                         12.216510\n",
      "dtype: float64\n",
      "Count of new data frame \n",
      "ID_num                  3307\n",
      "Incident_Description    3211\n",
      "Sub_Categories          3276\n",
      "Reason_Categories       2340\n",
      "Main_Categories         3307\n",
      "Incident_Date           3307\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Double Checking for NaN\n",
      "ID_num                    0\n",
      "Incident_Description     96\n",
      "Sub_Categories           31\n",
      "Reason_Categories       967\n",
      "Main_Categories           0\n",
      "Incident_Date             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#re-naming columns\n",
    "data_1= data_1.rename(columns ={'Nr.': 'ID_num', \"Beschrijving incident\": \"Incident_Description\", \"Subcategorie ongeval\": \"Sub_Categories\", \"Categorie ongeval\": \"Main_Categories\", \"Subcategorie(2) ongeval\": \"Reason_Categories\", \n",
    "                                \"Datum incident\": \"Incident_Date\" })\n",
    "\n",
    "\n",
    "#selecting the columns to work with\n",
    "ID_num = data_1[\"ID_num\"]\n",
    "Incident_Description = data_1[\"Incident_Description\"]\n",
    "Sub_Categories = data_1[\"Sub_Categories\"]\n",
    "Reason_Categories= data_1[\"Reason_Categories\"]\n",
    "Main_Categories= data_1[\"Main_Categories\"]\n",
    "Incident_Date= data_1[\"Incident_Date\" ]\n",
    "\n",
    "#creating a new dataframe\n",
    "c1= pd.Series(ID_num, name = \"ID_num\")\n",
    "c2= pd.Series(Incident_Description, name = \"Incident_Description\")\n",
    "c3= pd.Series(Sub_Categories, name= \"Sub_Categories\")\n",
    "c4= pd.Series(Reason_Categories ,name= \"Reason_Categories\")\n",
    "c5= pd.Series(Main_Categories, name= \"Main_Categories\")\n",
    "c6= pd.Series(Incident_Date, name= \"Incident_Date\")\n",
    "\n",
    "df = pd.concat([c1,c2,c3,c4,c5,c6], axis=1)\n",
    "print(df.shape)\n",
    "\n",
    "# EDA- Exploratory Data Analysis\n",
    "\n",
    "#number of entries for each column\n",
    "column_count= df.count()\n",
    "print (\"Column Count\")\n",
    "print(column_count)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "#number of null/NAN entries \n",
    "print(\"Null Count \") \n",
    "print(df.isnull().sum())\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "#Count of uniques entries\n",
    "a= df[\"Main_Categories\"].nunique()\n",
    "print(\"Unique_main_categories:\", a)\n",
    "c= df[\"Sub_Categories\"].nunique()\n",
    "print(\"Unique_subcategories:\", c)\n",
    "e= df[\"Reason_Categories\"].nunique()\n",
    "print(\"Unique_reasons:\", e)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "# class distribution Percentages \n",
    "class_dist= (df.groupby(\"Main_Categories\").size()/df[\"Main_Categories\"].count())*100\n",
    "print(class_dist)\n",
    "\n",
    "# removing nan\n",
    "df[\"Main_Categories\"].replace(r'^\\s+$', np.nan, regex=True)\n",
    "mc_df_1=df.dropna(subset=[\"Main_Categories\"])\n",
    "\n",
    "print(\"Count of new data frame \")\n",
    "print(mc_df_1.count())\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"Double Checking for NaN\")\n",
    "print(mc_df_1.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\byri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "C:\\Users\\byri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\byri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# removing noise from the data \n",
    "mc_df_1=mc_df_1[Main_Categories!=\"overig\"]  # other category adds no value to data and reduces model's performance\n",
    "mc_df_2= mc_df_1[Main_Categories!=\"Gevaarlijke atmosfeer\"] # too few entries, the machine learns nothing\n",
    "mc_df= mc_df_2[Main_Categories!=\"Gezondheidsschade\"] # too few entries, the machine learns nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******* PREPROCESSING ********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating stop words list, and lemmatizer  \n",
    "\n",
    "stopword_list = set(nltk.corpus.stopwords.words('dutch'))\n",
    "#add words that aren't in the NLTK stopwords list\n",
    "added_stopwords = ['+', '1e', '2e', '<', '>', 'a', 'a1', 'a12', 'a2', 'a9',\"één\", \"gis\", \"app\", \"h\", 'o.a.', 'oa', 'en/of']\n",
    "updated_stopword_list = stopword_list.union(added_stopwords)\n",
    "#print(updated_stopword_list)\n",
    "\n",
    "# Dutch spacy tokens \n",
    "nlp = nl_core_news_sm.load()\n",
    "\n",
    "def custom_lemmatizer(data):\n",
    "    return [(token.lemma_) for token in nlp(data) if not token.is_digit and not token.is_punct and not token.is_space]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********MODEL BUILDING********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "text = mc_df[\"Incident_Description\"].astype(str)\n",
    "label = mc_df[\"Main_Categories\"]\n",
    "# smote= SMOTE(\"auto\")\n",
    "#label, text = smote.fit_sample(label,text)\n",
    "text_train, text_test, label_train, label_test, = model_selection.train_test_split(text,label, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 𝑇𝐹×𝐼𝐷𝐹\n",
    "# word level tf-idf\n",
    "tfidf_vectorizer= TfidfVectorizer(max_features=12000,  stop_words=updated_stopword_list, max_df= 0.5, tokenizer=custom_lemmatizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\byri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "#fit & transform for cross validation \n",
    "train_tfidf = tfidf_vectorizer.fit(text)\n",
    "tfidf_text_v= train_tfidf.transform(text)\n",
    "# smote= SMOTE(\"auto\")\n",
    "# tfidf_text_v_train, text = smote.fit_sample(label,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform for test  & train\n",
    "tfidf_text_v_train= train_tfidf.transform(text_train)\n",
    "tfidf_text_v_test= train_tfidf.transform(text_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Score: 0.7395833333333334\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "SVM_cl= LinearSVC()\n",
    "SVM_cl.fit(tfidf_text_v_train, label_train)\n",
    "print (\"SVM Score:\", SVM_cl.score(tfidf_text_v_test, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM_P score (test): 0.7291666666666666\n",
      "SVM_P  score (training): 0.928695652173913\n"
     ]
    }
   ],
   "source": [
    "#SVM with L1 regularization \n",
    "#learning_rate=1, max_features=2, max_depth=2,\n",
    "SVM_cl_p= LinearSVC(penalty=\"l1\", loss='squared_hinge',dual=False )\n",
    "SVM_cl_p.fit(tfidf_text_v_train, label_train)\n",
    "#print (\"SVM_P Score:\", SVM_cl_p.score(tfidf_text_v_test, label_test))\n",
    "print(\"SVM_P score (test):\",SVM_cl_p.score(tfidf_text_v_test, label_test))\n",
    "print(\"SVM_P  score (training):\", SVM_cl_p.score(tfidf_text_v_train, label_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model_params= {\"svm\": {\"model\":svm.SVC(gamma=\"auto\"), \"params\": {\"C\": [1,10,20], \"kernel\":[\"rbf\", \"linear\"], \"penalty\":[\"l1\", \"L2\"], \"dual\": [\"False\", \"True\"], \"loss\":'squared_hinge' }}, \n",
    "              \"decision_tree\": {\"model\":DecisionTreeClassifier(),\"params\": {\"n_estimators\": [1,10,20], \"criterion\":['gini','entropy']}}, \n",
    "               \"naive_bayes\":{\"model\":MultinomialNB(),\"params\": {\"C\": [1,10,20]}},\n",
    "               \"kNN\":{\"model\":KNeighborsClassifier(),\"params\": { \"n_neighbors\":[3,5,10], \"weights\":[\"uniform\", \"distance\"], \"algorithm\":['ball_tree','kd_tree'] }},\n",
    "               \"xgb_cl\":{\"model\":xgb.XGBClassifier(random_state=4),\"params\": { \"n_estimators\": [1,50,10,100], \"learning_rate\":[0.1,0.5,1.0,2.0] }}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf= GridSearchCV(mp[\"model\"], mp [\"params\"], cv=5, return_train_score=False )\n",
    "clf.fit(tfidf_text_v_train, label_train)\n",
    "scores.append({\"model\": model_name, \"best_score\":clf.best_score_, \"best_params\": clf.best_params_})\n",
    "\n",
    "# classifiers.append(\n",
    "#     clf.grid_search_dummy_classifier(dict(\n",
    "#         strategy=['most_frequent','stratified','uniform'])))\n",
    "# df_gridS=pd.DataFrame(clf.cv_results_)\n",
    "# df_gridS[['param_C', 'param_kernel', 'mean_test_score','rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'fit_predict_measure'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-e55e73ce8f3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m imbalanced, imbalanced_classifiers = clf.fit_predict_measure(\n\u001b[0m\u001b[0;32m      2\u001b[0m     'Imbalanced', tfidf_text_v_train, tfidf_text_v_test, label_train,label_test, list(labels[0]), scores)\n\u001b[0;32m      3\u001b[0m \u001b[0mimbalanced\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'fit_predict_measure'"
     ]
    }
   ],
   "source": [
    "imbalanced, imbalanced_classifiers = clf.fit_predict_measure(\n",
    "    'Imbalanced', tfidf_text_v_train, tfidf_text_v_test, label_train,label_test, list(labels[0]), scores)\n",
    "imbalanced\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['param_kernel', 'param_C'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-9f4df913aa91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf_gridS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_gridS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'param_C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'param_kernel'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rank_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2984\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2986\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"loc\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not in index\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['param_kernel', 'param_C'] not in index\""
     ]
    }
   ],
   "source": [
    "clf.cv_results_\n",
    "df_gridS=pd.DataFrame(clf.cv_results_)\n",
    "df_gridS[['param_C', 'param_kernel', 'mean_test_score','rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model': 'xgb_cl', 'best_score': 0.6752173913043478, 'best_params': {'learning_rate': 0.5, 'n_estimators': 100}}]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params= {\"svm\": {\"model\":svm.SVC(gamma=\"auto\"), \"params\": {\"kernel\":[\"rbf\", \"linear\"]}}, \n",
    "              \"decision_tree\": {\"model\":DecisionTreeClassifier(), \"params\": {\"n_estimators\": [1,10,20]}}, \n",
    "               \"naive_bayes\":{\"model\":MultinomialNB(),\"params\": {\"params\": {\"C\": [1,10,20]}}},\n",
    "               \"kNN\":{\"model\":KNeighborsClassifier(),\"params\": { \"n_neighbors\":[5] }}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model': 'kNN', 'best_score': 0.6199999999999999, 'best_params': {'n_neighbors': 5}}]\n"
     ]
    }
   ],
   "source": [
    "scores=[]\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf= GridSearchCV(mp[\"model\"], mp [\"params\"], cv=5, return_train_score=False )\n",
    "clf.fit(tfidf_text_v_train, label_train)\n",
    "scores.append({\"model\": model_name, \"best_score\":clf.best_score_, \"best_params\": clf.best_params_})\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.69477353, 0.33213081, 0.74147754, 0.49249501, 0.71868982,\n",
       "        0.53139067]),\n",
       " 'std_fit_time': array([0.03860629, 0.00403855, 0.02723302, 0.03015224, 0.02241706,\n",
       "        0.00831969]),\n",
       " 'mean_score_time': array([0.07998576, 0.07877822, 0.08059487, 0.09414763, 0.07946672,\n",
       "        0.08856382]),\n",
       " 'std_score_time': array([0.00159548, 0.00141426, 0.00158695, 0.01088174, 0.00107235,\n",
       "        0.00146574]),\n",
       " 'param_C': masked_array(data=[1, 1, 10, 10, 20, 20],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'rbf'},\n",
       "  {'C': 20, 'kernel': 'linear'},\n",
       "  {'C': 20, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.68043478, 0.52391304, 0.67608696, 0.52391304, 0.66956522,\n",
       "        0.52391304]),\n",
       " 'split1_test_score': array([0.72391304, 0.52391304, 0.71304348, 0.52391304, 0.71304348,\n",
       "        0.52391304]),\n",
       " 'split2_test_score': array([0.70869565, 0.52173913, 0.6826087 , 0.52173913, 0.67826087,\n",
       "        0.52173913]),\n",
       " 'split3_test_score': array([0.72608696, 0.52391304, 0.70869565, 0.52391304, 0.70652174,\n",
       "        0.52391304]),\n",
       " 'split4_test_score': array([0.70652174, 0.52391304, 0.71304348, 0.52391304, 0.71521739,\n",
       "        0.52391304]),\n",
       " 'mean_test_score': array([0.70913043, 0.52347826, 0.69869565, 0.52347826, 0.69652174,\n",
       "        0.52347826]),\n",
       " 'std_test_score': array([0.01634921, 0.00086957, 0.01601039, 0.00086957, 0.01888178,\n",
       "        0.00086957]),\n",
       " 'rank_test_score': array([1, 4, 2, 4, 3, 4])}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svm.SVC(gamma=\"auto\"), {'C': [1,10,20], 'kernel': ['linear', 'rbf']},cv=5)\n",
    "clf.fit(tfidf_text_v_train, label_train)\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.709130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.523478</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.698696</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.523478</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.696522</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.523478</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_kernel  mean_test_score  rank_test_score\n",
       "0       1       linear         0.709130                1\n",
       "1       1          rbf         0.523478                4\n",
       "2      10       linear         0.698696                2\n",
       "3      10          rbf         0.523478                4\n",
       "4      20       linear         0.696522                3\n",
       "5      20          rbf         0.523478                4"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gridS=pd.DataFrame(clf.cv_results_)\n",
    "df_gridS[['param_C', 'param_kernel', 'mean_test_score','rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             precision    recall  f1-score   support\n",
      "\n",
      "                                 Aanrijding       0.73      0.69      0.71        32\n",
      "Agressie en extreme lichamelijke inspanning       1.00      0.18      0.30        17\n",
      "   Andere vormen van contact met voorwerpen       0.55      0.47      0.51        94\n",
      "                       BHV inzet op locatie       0.67      0.53      0.59        19\n",
      "    Gevaarlijke stoffen, brand en explosies       0.86      0.29      0.43        21\n",
      "                Machines en handgereedschap       0.66      0.58      0.62        86\n",
      "        Vallen (van personen of voorwerpen)       0.76      0.91      0.83       307\n",
      "\n",
      "                                   accuracy                           0.72       576\n",
      "                                  macro avg       0.75      0.52      0.57       576\n",
      "                               weighted avg       0.72      0.72      0.70       576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_predict_SVM= SVM_cl.predict(tfidf_text_v_test)\n",
    "print(classification_report(label_test, labels_predict_SVM))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22   0   0   0   0   1   9]\n",
      " [  1   3   3   0   0   0  10]\n",
      " [  0   0  44   2   0  17  31]\n",
      " [  0   0   0  10   0   0   9]\n",
      " [  1   0   3   0   6   1  10]\n",
      " [  3   0  13   1   1  50  18]\n",
      " [  3   0  17   2   0   7 278]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(label_test, labels_predict_SVM))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71527778 0.68       0.71304348 0.68695652 0.66434783]\n",
      "mean= 0.6919251207729469\n"
     ]
    }
   ],
   "source": [
    "results= cross_val_score(SVM_cl, tfidf_text_v, label, cv = 5)\n",
    "print(results)\n",
    "print(\"mean=\",results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class One-vs-One scheme compares every unique pairwise combination of classes\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True))\n",
    "y_score = classifier.fit(tfidf_text_v_train, label_train).decision_function(tfidf_text_v_test)\n",
    "\n",
    "\n",
    "y_prob = classifier.predict_proba(tfidf_text_v_test)\n",
    "\n",
    "macro_roc_auc_ovo = roc_auc_score( label_test, y_prob, multi_class=\"ovo\",\n",
    "                                  average=\"macro\")\n",
    "macro_roc_auc_ovr = roc_auc_score(label_test, y_prob, multi_class=\"ovr\",\n",
    "                                  average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-vs-One ROC AUC scores: 0.8472881488048246\n",
      "One-vs-Rest ROC AUC scores: 0.8625495688325764\n"
     ]
    }
   ],
   "source": [
    "print (\"One-vs-One ROC AUC scores:\", macro_roc_auc_ovo)\n",
    "print(\"One-vs-Rest ROC AUC scores:\" ,macro_roc_auc_ovr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Score: 0.65625\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "KNN_cl = KNeighborsClassifier()\n",
    "KNN_cl.fit(tfidf_text_v_train, label_train)\n",
    "print (\"KNN Score:\", KNN_cl.score(tfidf_text_v_test, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             precision    recall  f1-score   support\n",
      "\n",
      "                                 Aanrijding       0.89      0.53      0.67        32\n",
      "Agressie en extreme lichamelijke inspanning       0.00      0.00      0.00        17\n",
      "   Andere vormen van contact met voorwerpen       0.57      0.29      0.38        94\n",
      "                       BHV inzet op locatie       0.62      0.53      0.57        19\n",
      "    Gevaarlijke stoffen, brand en explosies       0.67      0.19      0.30        21\n",
      "                Machines en handgereedschap       0.48      0.47      0.47        86\n",
      "        Vallen (van personen of voorwerpen)       0.69      0.91      0.79       307\n",
      "\n",
      "                                   accuracy                           0.66       576\n",
      "                                  macro avg       0.56      0.42      0.45       576\n",
      "                               weighted avg       0.63      0.66      0.62       576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_predict_KNN= KNN_cl.predict(tfidf_text_v_test)\n",
    "print(classification_report(label_test, labels_predict_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 17   0   0   1   0   4  10]\n",
      " [  2   0   1   1   0   1  12]\n",
      " [  0   1  27   1   0  21  44]\n",
      " [  0   0   0  10   1   0   8]\n",
      " [  0   0   3   0   4   3  11]\n",
      " [  0   0   7   1   0  40  38]\n",
      " [  0   1   9   2   1  14 280]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(label_test, labels_predict_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55034722, 0.56347826, 0.54086957, 0.61217391, 0.53043478])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(KNN_cl, tfidf_text_v, label, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Score: 0.6319444444444444\n"
     ]
    }
   ],
   "source": [
    "#DT\n",
    "DT_cl = DecisionTreeClassifier()\n",
    "DT_cl.fit(tfidf_text_v_train, label_train)\n",
    "print (\"DT Score:\", DT_cl.score(tfidf_text_v_test, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             precision    recall  f1-score   support\n",
      "\n",
      "                                 Aanrijding       0.46      0.53      0.49        32\n",
      "Agressie en extreme lichamelijke inspanning       0.12      0.06      0.08        17\n",
      "   Andere vormen van contact met voorwerpen       0.46      0.41      0.44        94\n",
      "                       BHV inzet op locatie       0.56      0.47      0.51        19\n",
      "    Gevaarlijke stoffen, brand en explosies       0.40      0.19      0.26        21\n",
      "                Machines en handgereedschap       0.53      0.44      0.48        86\n",
      "        Vallen (van personen of voorwerpen)       0.73      0.83      0.78       307\n",
      "\n",
      "                                   accuracy                           0.63       576\n",
      "                                  macro avg       0.47      0.42      0.43       576\n",
      "                               weighted avg       0.61      0.63      0.62       576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_predict_DT= DT_cl.predict(tfidf_text_v_test)\n",
    "print(classification_report(label_test, labels_predict_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 17   2   2   0   1   2   8]\n",
      " [  1   1   4   1   0   0  10]\n",
      " [  1   1  39   1   1  15  36]\n",
      " [  1   0   0   9   0   0   9]\n",
      " [  3   0   3   0   4   2   9]\n",
      " [  3   1  19   1   3  38  21]\n",
      " [ 11   3  17   4   1  15 256]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(label_test, labels_predict_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61284722, 0.61565217, 0.60695652, 0.56173913, 0.51478261])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(DT_cl, tfidf_text_v, label, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6979166666666666"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cl=xgb.XGBClassifier(random_state=4)\n",
    "xgb_cl.fit(tfidf_text_v_train, label_train)\n",
    "xgb_cl.score(tfidf_text_v_test, label_test)\n",
    "print(\"Accuracy score (test):\",xgb_cl.score(tfidf_text_v_test, label_test))\n",
    "print(\"Accuracy score (training):\", xgb_cl.score(tfidf_text_v_train, label_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68055556, 0.68      , 0.66608696, 0.69391304, 0.60695652])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(xgb_cl, tfidf_text_v, label, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Score: 0.5885416666666666\n"
     ]
    }
   ],
   "source": [
    "# NB\n",
    "NB_cl= MultinomialNB()\n",
    "NB_cl.fit(tfidf_text_v_train, label_train)\n",
    "\n",
    "print (\"NB Score:\", NB_cl.score(tfidf_text_v_test, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             precision    recall  f1-score   support\n",
      "\n",
      "                                 Aanrijding       0.00      0.00      0.00        32\n",
      "Agressie en extreme lichamelijke inspanning       0.00      0.00      0.00        17\n",
      "   Andere vormen van contact met voorwerpen       0.91      0.11      0.19        94\n",
      "                       BHV inzet op locatie       1.00      0.26      0.42        19\n",
      "    Gevaarlijke stoffen, brand en explosies       0.00      0.00      0.00        21\n",
      "                Machines en handgereedschap       0.77      0.20      0.31        86\n",
      "        Vallen (van personen of voorwerpen)       0.57      1.00      0.73       307\n",
      "\n",
      "                                   accuracy                           0.59       576\n",
      "                                  macro avg       0.46      0.22      0.24       576\n",
      "                               weighted avg       0.60      0.59      0.48       576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\byri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "labels_predict_NB= NB_cl.predict(tfidf_text_v_test)\n",
    "print(classification_report(label_test, labels_predict_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0  32]\n",
      " [  0   0   0   0   0   0  17]\n",
      " [  0   0  10   0   0   5  79]\n",
      " [  0   0   0   5   0   0  14]\n",
      " [  0   0   1   0   0   0  20]\n",
      " [  0   0   0   0   0  17  69]\n",
      " [  0   0   0   0   0   0 307]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(label_test, labels_predict_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56597222, 0.55652174, 0.55826087, 0.57391304, 0.57217391])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(NB_cl, tfidf_text_v, label, cv = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6102125603864733\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'laplace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-c2596a74a544>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mNB_cl\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlaplace\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mNB_cl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_text_v_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#y_pred = gnb.fit(X_train, y_train).predict(X_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"NB Score:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNB_cl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_text_v_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'laplace'"
     ]
    }
   ],
   "source": [
    "\n",
    "NB_cl= MultinomialNB(Laplace= 0.5)\n",
    "NB_cl.fit(tfidf_text_v_train, label_train).predict(text_test)\n",
    "#y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print (\"NB Score:\", NB_cl.score(tfidf_text_v_test, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-vs-One ROC AUC scores:\n",
      "0.502078 (macro),\n",
      "0.499855 (weighted by prevalence)\n",
      "One-vs-Rest ROC AUC scores:\n",
      "0.503402 (macro),\n",
      "0.498358 (weighted by prevalence)\n"
     ]
    }
   ],
   "source": [
    "# multi-class One-vs-One scheme compares every unique pairwise combination of classes\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True))\n",
    "y_score = classifier.fit(tfidf_text_v_train, label_train).decision_function(tfidf_text_v_test)\n",
    "\n",
    "\n",
    "y_prob = classifier.predict_proba(tfidf_text_v_test)\n",
    "\n",
    "macro_roc_auc_ovo = roc_auc_score( label_test, y_prob, multi_class=\"ovo\",\n",
    "                                  average=\"macro\")\n",
    "weighted_roc_auc_ovo = roc_auc_score(label_test, y_prob, multi_class=\"ovo\",\n",
    "                                     average=\"weighted\")\n",
    "macro_roc_auc_ovr = roc_auc_score(label_test, y_prob, multi_class=\"ovr\",\n",
    "                                  average=\"macro\")\n",
    "weighted_roc_auc_ovr = roc_auc_score(label_test, y_prob, multi_class=\"ovr\",\n",
    "                                     average=\"weighted\")\n",
    "print(\"One-vs-One ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "      \"(weighted by prevalence)\"\n",
    "      .format(macro_roc_auc_ovo, weighted_roc_auc_ovo))\n",
    "print(\"One-vs-Rest ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "      \"(weighted by prevalence)\"\n",
    "      .format(macro_roc_auc_ovr, weighted_roc_auc_ovr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.sort_values of 0       2019-12-10\n",
       "1       2019-11-22\n",
       "2       2019-11-18\n",
       "3       2019-11-18\n",
       "4       2019-11-15\n",
       "           ...    \n",
       "18511   2007-04-20\n",
       "18512   2007-04-02\n",
       "18513   2006-12-11\n",
       "18514   2006-10-23\n",
       "18515   2006-09-11\n",
       "Name: Incident_Date, Length: 18516, dtype: datetime64[ns]>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Incident_Date\" ].sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: (1292, 5)\n",
      "Test Dataset: (17147, 5)\n"
     ]
    }
   ],
   "source": [
    "#Divide dataset equally- in 6.5 years\n",
    "df[\"Incident_Date\"] = pd.to_datetime(df[\"Incident_Date\"], format='%Y%m%d')\n",
    "df = df.set_index(\"Incident_Date\")\n",
    "df = df.sort_index()\n",
    "train = df['2006-09-11':'2013-05-10']\n",
    "test  = df['2013-06-11':]\n",
    "print('Train Dataset:',train.shape)\n",
    "print('Test Dataset:',test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: (4039, 5)\n",
      "Test Dataset: (14477, 5)\n"
     ]
    }
   ],
   "source": [
    "#Divide dataset 80:20 \n",
    "df[\"Incident_Date\"] = pd.to_datetime(df[\"Incident_Date\"], format='%Y%m%d')\n",
    "df = df.set_index(\"Incident_Date\")\n",
    "df = df.sort_index()\n",
    "train = df['2006-09-11':'2016-01-10']\n",
    "test  = df['2016-01-11':]\n",
    "print('Train Dataset:',train.shape)\n",
    "print('Test Dataset:',test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: (7585, 5)\n",
      "Test Dataset: (10931, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\byri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Divide dataset 90:10 \n",
    "mc_df[\"Incident_Date\"] = pd.to_datetime(mc_df[\"Incident_Date\"], format='%Y%m%d')\n",
    "mc_df = mc_df.set_index(\"Incident_Date\")\n",
    "mc_df = mc_df.sort_index()\n",
    "df_ey = mc_df['2006-09-11':'2017-04-10']\n",
    "df_ly  = mc_df['2017-04-11':]\n",
    "print('Train Dataset:',train.shape)\n",
    "print('Test Dataset:',test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "text_1 = df_ey[\"Incident_Description\"].astype(str)\n",
    "label_1 = df_ey[\"Main_Categories\"]\n",
    "text_1_train, text_1_test, label_1_train, label_1_test, = model_selection.train_test_split(text_1,label_1, test_size = 0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\byri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "train_tfidf = tfidf_vectorizer.fit(text_1)\n",
    "tfidf_text_v= train_tfidf.transform(text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform for test  & train\n",
    "tfidf_text_v_train= train_tfidf.transform(text_1_train)\n",
    "tfidf_text_v_test= train_tfidf.transform(text_1_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM_P score (test): 0.6548223350253807\n",
      "SVM_P  score (training): 0.9224904701397713\n"
     ]
    }
   ],
   "source": [
    "SVM_cl_p= LinearSVC(penalty=\"l1\", loss='squared_hinge',dual=False )\n",
    "SVM_cl_p.fit(tfidf_text_v_train, label_1_train)\n",
    "#print (\"SVM_P Score:\", SVM_cl_p.score(tfidf_text_v_test, label_test))\n",
    "print(\"SVM_P score (test):\",SVM_cl_p.score(tfidf_text_v_test, label_1_test))\n",
    "print(\"SVM_P  score (training):\", SVM_cl_p.score(tfidf_text_v_train, label_1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-296694f63432>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_ly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMain_Categories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSVM_cl_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# results[\"text_1\"].append(test_feature_label_frame[\"path\"][i])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# results[\"label_1\"].append(classes[index])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "classes = list(np.unique(df_ly.Main_Categories))\n",
    "for i in range 0,df_ly[\"Incident_Description\"].size\n",
    "prob=SVM_cl_p.predict()\n",
    "index=np.argmax(prob[0])\n",
    "# results[\"text_1\"].append(test_feature_label_frame[\"path\"][i])\n",
    "# results[\"label_1\"].append(classes[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-22d4b225729d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_ly\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Incident_Description\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "df_ly[\"Incident_Description\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(787,)\n"
     ]
    }
   ],
   "source": [
    "print(text_1_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit7f6d5ef80ac84f0dbc4f0d76a489c0fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}